{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Table detector"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Colab requirements"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Before restarting runtime (remember to select GPU runtime)$\\dots$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Wadaboa/table-detector.git\n",
    "!pip install -r table-detector/init/colab_requirements.txt"
   ]
  },
  {
   "source": [
    "After restarting runtime$\\dots$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.insert(0, \"table-detector\")\n",
    "os.chdir(\"table-detector\")"
   ]
  },
  {
   "source": [
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import wandb\n",
    "import yaml\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, fixed\n",
    "\n",
    "import learning\n",
    "import transforms\n",
    "import detectors\n",
    "import utils\n",
    "import train\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "## Initialization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Matplotlib"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 12]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['axes.xmargin'] = .05\n",
    "plt.rcParams['axes.ymargin'] = .05\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "source": [
    "### Weights & biases"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb enabled"
   ]
  },
  {
   "source": [
    "### PyTorch and numpy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "DEVICE = utils.get_device()\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEVICE.type != \"cpu\":\n",
    "    !nvidia-smi"
   ]
  },
  {
   "source": [
    "## Utils"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    np_img = utils.to_numpy(img)\n",
    "    plt.imshow(np_img)\n",
    "\n",
    "def draw_predictions(dataset, index, model, conf_thresh=0.5, width=4):\n",
    "    images = []\n",
    "    for image, _ in dataset[index]:\n",
    "        output = model([image.to(DEVICE)])[0]\n",
    "        boxes = output[\"boxes\"][output[\"scores\"] >= conf_thresh]\n",
    "        colors = utils.generate_colors(len(boxes))\n",
    "        img = utils.draw_bounding_boxes(\n",
    "            utils.denormalize_image(image), boxes, width=width, colors=colors\n",
    "        )\n",
    "        images.append(img)\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "    show(grid)\n",
    "\n",
    "def draw_targets(dataset, index, width=4):\n",
    "    images = []\n",
    "    for image, target in dataset[index]:\n",
    "        colors = utils.generate_colors(len(target[\"boxes\"]))\n",
    "        img = utils.draw_bounding_boxes(\n",
    "            utils.denormalize_image(image), target[\"boxes\"], width=width, colors=colors\n",
    "        )\n",
    "        images.append(img)\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "    show(grid)"
   ]
  },
  {
   "source": [
    "## Data loading"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'dataset': {'train': 'marmot',\n",
       "  'val': 'marmot',\n",
       "  'dummy': {'enabled': False, 'size': 10},\n",
       "  'marmot': {'path': ['datasets/marmot/table_recognition/data/english/positive',\n",
       "    'datasets/marmot/table_recognition/data/chinese/positive']},\n",
       "  'icdar13': {'path': ['datasets/icdar13/icdar2013-competition-dataset-with-gt/competition-dataset-eu',\n",
       "    'datasets/icdar13/icdar2013-competition-dataset-with-gt/competition-dataset-us']}},\n",
       " 'generic': {'random_seed': 42,\n",
       "  'workers': 4,\n",
       "  'device': 'cpu',\n",
       "  'wandb': {'enabled': False,\n",
       "   'project': 'table-detector',\n",
       "   'entity': 'wadaboa',\n",
       "   'watch': 'all'}},\n",
       " 'training': {'train_split': 0.8,\n",
       "  'epochs': 28,\n",
       "  'log_interval': 1,\n",
       "  'batch_size': 2,\n",
       "  'checkpoints': {'save': True, 'frequency': 3, 'path': 'checkpoints'}},\n",
       " 'backbone': {'family': 'vgg',\n",
       "  'type': 'vgg16',\n",
       "  'pretrained': True,\n",
       "  'input_size': {'exact': {'width': 224, 'height': 224},\n",
       "   'bound': {'min': 800, 'max': 1300}},\n",
       "  'imagenet_params': {'mean': [0.485, 0.456, 0.406],\n",
       "   'std': [0.229, 0.224, 0.225]}},\n",
       " 'detector': {'type': 'faster_rcnn',\n",
       "  'region_proposals': {'type': 'edge_boxes',\n",
       "   'max_proposals': 10,\n",
       "   'selective_search': {'type': 'quality',\n",
       "    'strategies': {'color': True,\n",
       "     'fill': True,\n",
       "     'size': True,\n",
       "     'texture': True}},\n",
       "   'edge_boxes': {'model_path': 'models/edge_boxes.gz',\n",
       "    'alpha': 0.65,\n",
       "    'beta': 0.75}},\n",
       "  'box_score_thresh': 0.5,\n",
       "  'box_nms_thresh': 0.5,\n",
       "  'box_detections_per_img': 100,\n",
       "  'box_fg_iou_thresh': 0.5,\n",
       "  'box_bg_iou_thresh': 0.5,\n",
       "  'box_batch_size_per_image': 512,\n",
       "  'box_positive_fraction': 0.25,\n",
       "  'box_regression_weights': [10.0, 10.0, 5.0, 5.0],\n",
       "  'faster_rcnn': {'anchors': {'sizes': [128, 256, 512],\n",
       "    'ratios': [0.5, 1.0, 2.0]}}},\n",
       " 'optimizers': {'type': 'adam',\n",
       "  'adam': {'lr': 0.001, 'weight_decay': 0.0, 'amsgrad': False},\n",
       "  'rmsprop': {'lr': 0.01, 'momentum': 0.0, 'alpha': 0.99, 'weight_decay': 0.0},\n",
       "  'sgd': {'lr': 0.001,\n",
       "   'momentum': 0.0,\n",
       "   'weight_decay': 0.0,\n",
       "   'nesterov': False}},\n",
       " 'lr_schedulers': {'type': 'none',\n",
       "  'step': {'step_size': 30, 'gamma': 0.1, 'last_epoch': -1},\n",
       "  'multi_step': {'milestones': [30, 80], 'gamma': 0.1, 'last_epoch': -1}}}"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "with open('parameters.yml', 'r') as conf:\n",
    "    args = yaml.load(conf, Loader=yaml.FullLoader)\n",
    "params = utils.Struct(**args)\n",
    "params.generic.device = DEVICE\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = train.get_dataset(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=10, description='index', max=766), IntSlider(value=4, description='width…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19be6011091e4129b924dc9f380d451d"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "interact(\n",
    "    draw_targets, \n",
    "    dataset=fixed(train_dataset), \n",
    "    index=widgets.IntSlider(min=0, max=len(train_dataset), step=1, value=10)\n",
    ");"
   ]
  },
  {
   "source": [
    "## Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = train.get_train_dataloader(params, train_dataset)\n",
    "test_dataloader = train.get_test_dataloader(params, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.detector.type = \"fast_rcnn\"\n",
    "detector = detectors.get_detector(params, train.NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.wandb_init(params, args)\n",
    "train.wandb_watch(params, detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = train.get_optimizer(params, detector)\n",
    "lr_scheduler = train.get_lr_scheduler(params, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-7212b4eebaec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m learning.training_loop(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m~/Github/table-detector/src/learning.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(params, model, optimizer, train_dataloader, val_dataloader, lr_scheduler)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;31m# Train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;31m# Decay the learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/table-detector/src/learning.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(params, model, optimizer, dataloader, epoch)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;31m# Aggregate losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/table-detector/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/table-detector/src/detectors.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m    341\u001b[0m            \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moutput\u001b[0m \u001b[0mof\u001b[0m \u001b[0mROI\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         '''\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;31m# Perform the following transformations:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning.training_loop(\n",
    "    params, detector, optimizer, train_dataloader,\n",
    "    test_dataloader, lr_scheduler=lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.wandb_finish(params)"
   ]
  },
  {
   "source": [
    "## Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "interactive(children=(IntSlider(value=10, description='index', max=192), FloatSlider(value=0.5, description='c…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe37b163b1b6481db13789fac1c5abd9"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "interact(\n",
    "    draw_predictions, \n",
    "    dataset=fixed(test_dataset),\n",
    "    index=widgets.IntSlider(min=0, max=len(test_dataset), step=1, value=10),\n",
    "    model=fixed(detector),\n",
    "    conf_thresh=widgets.FloatSlider(min=0.0, max=1.0, step=0.05, value=0.5)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}