# Datasets configuration
dataset:
  # Dataset to use for training
  train: marmot
  # Dataset to use for validation
  val: marmot
  # Use a small slice of data to debug
  dummy:
    # Enable or disable
    enabled: True
    # Number of examples to use
    size: 10
  # Marmot dataset configuration
  marmot:
    # Path to Marmot examples
    path:
      - datasets/marmot/table_recognition/data/english/positive
      #- datasets/marmot/table_recognition/data/english/negative
      #- datasets/marmot/table_recognition/data/chinese/positive
      #- datasets/marmot/table_recognition/data/chinese/negative

# Generic configuration
generic:
  # Random seed for all the randomness sources
  random_seed: 24
  # Number of data loading workers
  workers: 4
  # Where should data be processed
  device: cpu

# Training configuration
training:
  # How much data to use for training
  train_split: !!float 0.8
  # Number of training epochs
  epochs: 10
  # How often to print and log metrics
  log_interval: 1
  # Batch size
  batch_size: 2
  # How to handle model checkpoints during training
  checkpoints:
    # Enable or disable saving checkpoints
    save: True
    # How often to save checkpoints (epochs)
    frequency: 3
    # Where to save checkpoints
    path: checkpoints

# What ImageNet backbone to use
backbone:
  # Family of the backbone
  # Types: alexnet, densenet, mobilenet, resnet, vgg
  family: mobilenet
  # Actual backbone to use (among the ones in the above family)
  # See https://github.com/pytorch/vision/tree/master/torchvision/models
  type: mobilenet_v2
  # If pretrained or not
  pretrained: True
  # Desired input size
  # (check backbones.py to see minimum sizes for each model)
  input_size:
    # Inputs will be rescaled to the exact specified size
    exact:
      # Backbone input width
      width: 224
      # Backbone input height
      height: 224
    # Inputs will be rescaled to a squares, respecting the
    # given size bounds
    bound:
      # Minimum size
      min: 800
      # Maximum size
      max: 1300
  # ImageNet images standard deviation (0-1 range)
  imagenet_params:
    # ImageNet images mean
    mean:
      - !!float 0.485
      - !!float 0.456
      - !!float 0.406
    # ImageNet images standard deviation
    std:
      - !!float 0.229
      - !!float 0.224
      - !!float 0.225

# What model to use for table detection
detector:
  # Actual detector to use
  # Types: rcnn, fast_rcnn, faster_rcnn
  type: faster_rcnn

  # Standard region proposals configuration
  region_proposals:
    # Region proposal algorithm
    type: edge_boxes
    # Number of maximum proposals per image
    max_proposals: 10
    # Selective search configuration
    selective_search:
      # Selective search type
      # Types: fast, quality
      type: quality
      # Selective search strategies
      strategies:
        # Color strategy
        color: True
        # Fill strategy
        fill: True
        # Size strategy
        size: True
        # Texture strategy
        texture: True
    # Edge boxes configuration
    edge_boxes:
      # Path to the edge boxes model
      # (https://github.com/opencv/opencv_extra/blob/master/testdata/cv/ximgproc/model.yml.gz)
      model_path: models/edge_boxes.gz
      # Step size of sliding window search
      alpha: !!float 0.65
      # NMS threshold for object proposal
      beta: !!float 0.75

  # During inference, only return proposals with a classification score
  # greater than the following parameter
  box_score_thresh: !!float 0.5
  # NMS threshold for the prediction head (used during inference)
  box_nms_thresh: !!float 0.5
  # Maximum number of detections per image, for all classes
  box_detections_per_img: 100
  # Minimum IoU between the proposals and the GT box so that they can be
  # considered as positive during training of the classification head
  box_fg_iou_thresh: !!float 0.5
  # Maximum IoU between the proposals and the GT box so that they can be
  # considered as negative during training of the classification head
  box_bg_iou_thresh: !!float 0.5
  # Number of proposals that are sampled during training of the
  # classification head
  box_batch_size_per_image: 512
  # Proportion of positive proposals in a mini-batch during training
  # of the classification head
  box_positive_fraction: !!float 0.25
  # Weights for the encoding/decoding of the bounding boxes
  box_regression_weights:
    - !!float 10.0 # x
    - !!float 10.0 # y
    - !!float 5.0 # w
    - !!float 5.0 # h

  # Faster R-CNN configuration
  faster_rcnn:
    # Anchors generation configuration
    anchors:
      # Anchor sizes for one feature map
      sizes:
        - 128
        - 256
        - 512
      # Anchors aspect ratios for one feature map
      ratios:
        - !!float 0.5
        - !!float 1.0
        - !!float 2.0

# What optimizer to use for gradient descent
optimizers:
  # Type of optimizer
  type: adam
  # Adam optimizer
  adam:
    # Learning rate
    lr: !!float 0.001
    # L2 penalty
    weight_decay: !!float 0
    # Whether to use the AMSGrad variant of this algorithm
    amsgrad: False
  # RMSProp optimizer
  rmsprop:
    # Learning rate
    lr: !!float 0.01
    # Momentum factor
    momentum: !!float 0
    # Smoothing constant
    alpha: !!float 0.99
    # L2 penalty
    weight_decay: !!float 0
  # Stochastic Gradient Descent with momentum optimizer
  sgd:
    # Learning rate
    lr: !!float 0.001
    # Momentum factor
    momentum: !!float 0
    # L2 penalty
    weight_decay: !!float 0
    # Enables Nesterov momentum
    nesterov: False

# How to decay the learning rate during training
lr_schedulers:
  # Type of learning rate scheduler
  type: none
  # Step scheduler
  step:
    # Period of learning rate decay
    step_size: 30
    # Multiplicative factor of learning rate decay
    gamma: !!float 0.1
    # The index of last epoch
    last_epoch: -1
  # Multi step scheduler
  multi_step:
    # List of epoch indices (must be increasing)
    milestones:
      - 30
      - 80
    # Multiplicative factor of learning rate decay
    gamma: 0.1
    # The index of last epoch
    last_epoch: -1
